{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda974f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "punct = str.maketrans(\"\",\"\",\"!.,:;-?\")\n",
    "\n",
    "def clean_line(line):\n",
    "    \"\"\"changes case and removes punctuation\"\"\"\n",
    "\n",
    "    # make all one case\n",
    "    cleaned_line = line.lower()\n",
    "        \n",
    "    # remove punctuation\n",
    "    cleaned_line = cleaned_line.translate(punct)\n",
    "    return cleaned_line\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d513c5ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('call', 1), ('ishmael', 1), ('years', 1), ('agonever', 1), ('mind', 1), ('how', 1), ('long', 1), ('precisely', 1), ('having', 1), ('no', 1), ('money', 1), ('purse', 1), ('particular', 1), ('interest', 1), ('on', 1), ('shore', 1), ('thought', 1), ('would', 1), ('sail', 1), ('see', 1), ('watery', 1), ('part', 1), ('world', 1), ('way', 1), ('have', 1), ('driving', 1), ('off', 1), ('spleen', 1), ('regulating', 1), ('circulation', 1), ('growing', 1), ('grim', 1), ('mouth', 1), ('damp', 1), ('drizzly', 1), ('november', 1), ('soul', 1), ('involuntarily', 1), ('pausing', 1), ('before', 1), ('coffin', 1), ('warehouses', 1), ('bringing', 1), ('up', 1), ('rear', 1), ('every', 1), ('funeral', 1), ('meet', 1), ('especially', 1), ('hypos', 1), ('such', 1), ('an', 1), ('upper', 1), ('hand', 1), ('requires', 1), ('strong', 1), ('moral', 1), ('principle', 1), ('prevent', 1), ('from', 1), ('deliberately', 1), ('stepping', 1), ('into', 1), ('street', 1), ('methodically', 1), ('knocking', 1), (\"people's\", 1), ('hats', 1), ('offthen', 1), ('account', 1), ('high', 1), ('sea', 1), ('soon', 1), ('can', 1), ('substitute', 1), ('for', 1), ('pistol', 1), ('ball', 1), ('philosophical', 1), ('flourish', 1), ('cato', 1), ('throws', 1), ('himself', 1), ('upon', 1), ('his', 1), ('sword', 1), ('quietly', 1), ('ship', 1), ('surprising', 1), ('if', 1), ('they', 1), ('but', 1), ('knew', 1), ('almost', 1), ('all', 1), ('men', 1), ('their', 1), ('degree', 1), ('other', 1), ('cherish', 1), ('very', 1), ('nearly', 1), ('same', 1), ('feelings', 1), ('towards', 1), ('ocean', 1), ('now', 1), ('your', 1), ('insular', 1), ('city', 1), ('manhattoes', 1), ('belted', 1), ('round', 1), ('wharves', 1), ('indian', 1), ('isles', 1), ('coral', 1), ('reefscommerce', 1), ('surrounds', 1), ('her', 1), ('surf', 1), ('right', 1), ('left', 1), ('streets', 1), ('you', 1), ('waterward', 1), ('its', 1), ('extreme', 1), ('downtown', 1), ('battery', 1), ('where', 1), ('noble', 1), ('mole', 1), ('washed', 1), ('waves', 1), ('cooled', 1), ('breezes', 1), ('which', 1), ('few', 1), ('hours', 1), ('previous', 1), ('were', 1), ('out', 1), ('sight', 1), ('land', 1), ('look', 1), ('at', 1), ('crowds', 1), ('watergazers', 1), ('some', 2), ('little', 2), ('or', 2), ('nothing', 2), ('about', 2), ('find', 2), ('myself', 2), ('get', 2), ('that', 2), ('time', 2), ('this', 2), ('take', 2), ('as', 3), ('with', 3), ('there', 3), ('in', 4), ('my', 4), ('whenever', 4), ('by', 4), ('me', 5), ('to', 5), ('a', 6), ('it', 6), ('is', 7), ('of', 8), ('and', 9), ('i', 9), ('the', 14)]\n",
      "Most common words:\n",
      "('the', 14)\n",
      "('i', 9)\n",
      "('and', 9)\n",
      "('of', 8)\n",
      "('is', 7)\n",
      "\n",
      "Least common words:\n",
      "('call', 1)\n",
      "('ishmael', 1)\n",
      "('years', 1)\n",
      "('agonever', 1)\n",
      "('mind', 1)\n"
     ]
    }
   ],
   "source": [
    "# punct = str.maketrans(\"\",  \"\", \"!.,:;-?\")#最後一個字串代表要刪除的東西，不會產生空格\n",
    "#                                          #第一個參數會被第二個參數取代，以本案例，只是要刪除東西，沒有要取代\n",
    "\n",
    "# def clean_line(line):\n",
    "#     \"\"\"changes case and removes punctuation\"\"\"\n",
    "#     # make all one case\n",
    "#     cleaned_line = line.lower()\n",
    "        \n",
    "#     # remove punctuation\n",
    "#     cleaned_line = cleaned_line.translate(punct)\n",
    "#     return cleaned_line\n",
    "\n",
    "# def get_words(line):\n",
    "#     \"\"\"splits line into words, and rejoins with newlines\"\"\"\n",
    "#     words = line.split()\n",
    "#     #print(\"\\n\".join(words) + \"\\n\")\n",
    "#     return \"\\n\".join(words) + \"\\n\"\n",
    "     \n",
    "    \n",
    "# with open(\"moby_01.txt\") as infile, open(\"moby_01_clean.txt\", \"w\") as outfile:\n",
    "#     for line in infile:\n",
    "#         cleaned_line = clean_line(line)\n",
    "#         cleaned_words = get_words(cleaned_line)\n",
    "        \n",
    "#         # write all words for line\n",
    "#         outfile.write(cleaned_words)\n",
    "\n",
    "# def count_words(words):\n",
    "#     \"\"\"takes list of cleaned words, returns count dictionary\"\"\"\n",
    "#     word_count = {}\n",
    "#     #print(moby_words)\n",
    "#     for word in moby_words:\n",
    "#         count = word_count.setdefault(word, 0)\n",
    "#         word_count[word] += 1\n",
    "#     return word_count\n",
    "\n",
    "# def word_stats(word_count):\n",
    "#     \"\"\"Takes word count dictionary and returns top and bottom five \n",
    "#        entries\"\"\"\n",
    "#     word_list = list(word_count.items())\n",
    "#     word_list.sort(key=lambda x: x[1])\n",
    "#     print(word_list)\n",
    "#     least_common = word_list[:5]\n",
    "#     most_common = word_list[-1:-6:-1]#-1可以倒過來顯示\n",
    "#     return most_common, least_common\n",
    "\n",
    "# moby_words = []\n",
    "# with open('moby_01_clean.txt') as infile:\n",
    "#     for word in infile:\n",
    "#         if word.strip():\n",
    "#             moby_words.append(word.strip())\n",
    "        \n",
    "# word_count = count_words(moby_words)\n",
    "# most, least = word_stats(word_count)\n",
    "\n",
    "# print(\"Most common words:\")\n",
    "# for word in most:\n",
    "#     print(word)\n",
    "\n",
    "# print(\"\\nLeast common words:\")\n",
    "# for word in least:\n",
    "#     print(word)\n",
    "\n",
    "# infile = open(\"moby_01.txt\")\n",
    "# lines = infile.read()\n",
    "# a = clean_line(lines)\n",
    "# get_words(a)\n",
    "# clean_line.__doc__\n",
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
